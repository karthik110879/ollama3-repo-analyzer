#!/usr/bin/env node

/**
 * Model Setup Script for AI Repository Analyzer
 * 
 * This script helps you install and test the recommended Ollama models
 * for optimal codebase analysis and diagram generation.
 */

const { execSync } = require('child_process');
const { getAvailableModels, getModelConfig, getRecommendedModel } = require('../src/config/modelConfig');

class ModelSetup {
  constructor() {
    this.installedModels = [];
    this.availableModels = getAvailableModels('codeAnalysis');
  }

  /**
   * Check if Ollama is running
   */
  checkOllamaStatus() {
    try {
      execSync('ollama list', { stdio: 'pipe' });
      console.log('‚úÖ Ollama is running');
      return true;
    } catch (error) {
      console.error('‚ùå Ollama is not running or not installed');
      console.error('Please install Ollama from https://ollama.com and start it');
      return false;
    }
  }

  /**
   * Get list of currently installed models
   */
  getInstalledModels() {
    try {
      const output = execSync('ollama list', { encoding: 'utf8' });
      const lines = output.split('\n').slice(1); // Skip header
      this.installedModels = lines
        .filter(line => line.trim())
        .map(line => line.split(/\s+/)[0])
        .filter(model => model);
      
      console.log(`üìã Found ${this.installedModels.length} installed models`);
      return this.installedModels;
    } catch (error) {
      console.error('‚ùå Failed to get installed models:', error.message);
      return [];
    }
  }

  /**
   * Install a model
   */
  async installModel(modelName) {
    try {
      console.log(`üì• Installing ${modelName}...`);
      execSync(`ollama pull ${modelName}`, { stdio: 'inherit' });
      console.log(`‚úÖ Successfully installed ${modelName}`);
      return true;
    } catch (error) {
      console.error(`‚ùå Failed to install ${modelName}:`, error.message);
      return false;
    }
  }

  /**
   * Test a model with a simple code analysis
   */
  async testModel(modelName) {
    try {
      console.log(`üß™ Testing ${modelName}...`);
      
      const testPrompt = `Analyze this simple code structure and return JSON:
      - src/
        - app.js
        - routes/
          - api.js
        - models/
          - user.js
      - package.json
      
      Return only JSON with architecture_pattern, tech_stack, and key_components.`;
      
      const command = `echo "${testPrompt}" | ollama run ${modelName}`;
      const output = execSync(command, { encoding: 'utf8', timeout: 30000 });
      
      // Check if output contains JSON
      if (output.includes('{') && output.includes('}')) {
        console.log(`‚úÖ ${modelName} test passed`);
        return true;
      } else {
        console.log(`‚ö†Ô∏è ${modelName} test inconclusive - output may not be JSON`);
        return false;
      }
    } catch (error) {
      console.error(`‚ùå ${modelName} test failed:`, error.message);
      return false;
    }
  }

  /**
   * Show model recommendations based on system resources
   */
  showRecommendations() {
    console.log('\nüéØ Model Recommendations:');
    console.log('========================');
    
    const resourceLevels = ['low', 'medium', 'high'];
    
    resourceLevels.forEach(level => {
      const recommended = getRecommendedModel('codeAnalysis', level);
      const config = getModelConfig('codeAnalysis', recommended);
      
      console.log(`\n${level.toUpperCase()} RESOURCES (${config.resourceRequirements}):`);
      console.log(`  Model: ${recommended}`);
      console.log(`  Name: ${config.name}`);
      console.log(`  Description: ${config.description}`);
      console.log(`  Strengths: ${config.strengths.join(', ')}`);
    });
  }

  /**
   * Interactive model selection and installation
   */
  async interactiveSetup() {
    console.log('\nüöÄ AI Repository Analyzer - Model Setup');
    console.log('=====================================\n');

    if (!this.checkOllamaStatus()) {
      return;
    }

    this.getInstalledModels();
    this.showRecommendations();

    console.log('\nüìã Available Code Analysis Models:');
    console.log('==================================');
    
    this.availableModels.forEach((model, index) => {
      const config = getModelConfig('codeAnalysis', model);
      const isInstalled = this.installedModels.includes(model);
      const status = isInstalled ? '‚úÖ Installed' : '‚ùå Not installed';
      
      console.log(`${index + 1}. ${model} (${config.name})`);
      console.log(`   ${status} | ${config.resourceRequirements}`);
      console.log(`   ${config.description}`);
      console.log('');
    });

    // Check if any recommended models are installed
    const recommendedModels = ['codellama:13b-instruct', 'codellama:34b-instruct', 'deepseek-coder:6.7b-instruct'];
    const installedRecommended = recommendedModels.filter(model => this.installedModels.includes(model));
    
    if (installedRecommended.length > 0) {
      console.log('‚úÖ You have recommended models installed!');
      console.log('Installed recommended models:', installedRecommended.join(', '));
    } else {
      console.log('‚ö†Ô∏è No recommended models installed. Consider installing one of the recommended models above.');
    }

    console.log('\nüí° To install a model, run:');
    console.log('   ollama pull <model-name>');
    console.log('\nüí° To test a model, run:');
    console.log('   ollama run <model-name>');
  }

  /**
   * Quick setup with automatic installation of recommended model
   */
  async quickSetup(resourceLevel = 'medium') {
    console.log('\nüöÄ Quick Setup - Installing Recommended Model');
    console.log('============================================\n');

    if (!this.checkOllamaStatus()) {
      return;
    }

    const recommendedModel = getRecommendedModel('codeAnalysis', resourceLevel);
    const config = getModelConfig('codeAnalysis', recommendedModel);
    
    console.log(`üéØ Installing recommended model for ${resourceLevel} resources:`);
    console.log(`   Model: ${recommendedModel}`);
    console.log(`   Name: ${config.name}`);
    console.log(`   Requirements: ${config.resourceRequirements}\n`);

    const success = await this.installModel(recommendedModel);
    
    if (success) {
      console.log('\nüß™ Testing the installed model...');
      const testPassed = await this.testModel(recommendedModel);
      
      if (testPassed) {
        console.log('\nüéâ Setup completed successfully!');
        console.log(`Your Repository Analyzer Agent will now use ${recommendedModel}`);
      } else {
        console.log('\n‚ö†Ô∏è Setup completed but model test was inconclusive');
        console.log('The model is installed but may need manual testing');
      }
    } else {
      console.log('\n‚ùå Setup failed. Please check the error messages above.');
    }
  }
}

// Command line interface
async function main() {
  const setup = new ModelSetup();
  const args = process.argv.slice(2);
  
  if (args.includes('--quick') || args.includes('-q')) {
    const resourceLevel = args.find(arg => arg.startsWith('--resources='))?.split('=')[1] || 'medium';
    await setup.quickSetup(resourceLevel);
  } else {
    await setup.interactiveSetup();
  }
}

if (require.main === module) {
  main().catch(console.error);
}

module.exports = ModelSetup;
